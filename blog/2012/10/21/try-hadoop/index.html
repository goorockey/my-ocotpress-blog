
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>玩一下hadoop - Goorockey's Blog</title>
	<meta name="author" content="Goorockey">

	
	<meta name="description" content="由于某种原因，今天玩了一下Hadoop。正确来说，我是玩HOP，一个Hadoop的修改版本。 The Hadoop Online Prototype (HOP) is a modified version of Hadoop MapReduce that allows data to be &hellip;">
	
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="http://feed.goorockey.com" rel="alternate" title="Goorockey's Blog" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script async="true" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">Goorockey's Blog</a></h1>
<nav id="main-nav"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
	<li><a href="/links.html">Links</a></li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
	<li><a href="/links.html">Links</a></li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:www.goorockey.com">
			</form>
		</div>
	</div>
</nav>
<nav id="sub-nav" class="alignright">
	<div class="social">
		
		
		
		
		<a class="github" href="https://github.com/goorockey" title="GitHub">GitHub</a>
		
    
		
		
		
		
		
		<a class="rss" href="http://feed.goorockey.com" title="RSS">RSS</a>
		
    
	</div>
	<form class="search" action="http://google.com/search" method="get">
		<input class="alignright" type="text" name="q" results="0">
		<input type="hidden" name="q" value="site:www.goorockey.com">
	</form>
</nav>

</header>
	
		
	
	<div id="content" class="inner"><article class="post">
	<h2 class="title">玩一下hadoop</h2>
	<div class="entry-content">
<p>由于某种原因，今天玩了一下<a href="http://hadoop.apache.org/" title="Hadoop">Hadoop</a>。正确来说，我是玩<a href="http://code.google.com/p/hop/" title="HOP">HOP</a>，一个Hadoop的修改版本。</p>

<blockquote><p>The Hadoop Online Prototype (HOP) is a modified version of Hadoop MapReduce that allows data to be pipelined between tasks and between jobs. This can enable better cluster utilization and increased parallelism, and allows new functionality: online aggregation (approximate answers as a job runs), and stream processing (MapReduce jobs that run continuously, processing new data as it arrives).</p></blockquote>

<p>就是多了pipeline（流水线）的Hadoop。分布式流水线可以有效加快各jobs在各节点的同步运算。</p>

<!-- more -->

<h3 id="section">准备</h3>

<p>我是在linux上弄的，windows下用cygwin也行。</p>

<p>下载HOP压缩包后，看里面的docs就够了，同时src/example还有一些例子。</p>

<p>确保ssh,sshd,rsync,jdk都有了。同时要保证ssh localhost不要输入密码的认证步骤。具体docs/quickstart也有说，可以这样：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
</span><span class="line">$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后是设置jdk的目录，修改conf/hadoop-env.sh中JAVA_HOME。一般为/usr/lib/jvm/下的某个java目录，我就直接写成/usr/lib/jvm/default-java了。</p>

<p>这时候执行bin/hadoop就会出现帮助信息了。</p>

<h3 id="section-1">跑例程</h3>

<p>Hadoop的文件系统叫<a href="http://hadoop.apache.org/docs/stable/hdfs_design.html" title="HDFS">HDFS</a>（Hadoop distribution filesystem)，是一个分布式文件系统。每份数据都会在多个节点有备份，以容错、修复。所有数据都要先放进HDFS才能Hadoop处理。</p>

<p>Hadoop的分布式体系中，有一个NameNode，是master的角色，负责主控各节点，有多个DataNode，是slave，负责真正存储数据。这些可以在conf/master和conf/slave设置。
同时还有一个JobTracker，负责调度jobs，默认就是NameNode这个主机一起充当NameNode，这个在conf/hadoop-site.xml设置。另外所有DataNode都是TaskTracker，负责执行jobs。具体更多对conf/hadoop-site.xml的配置参看docs/cluster_setup.html</p>

<p>执行bin/hadoop namenode -format，会创造一个namenode。文件都已某种格式放在/tmp/hadoop-“hostname”那里。</p>

<p>执行bin/start-all.sh会启动hadoop，默认通过http://localhost:50070/可以访问NameNode，http://localhost:50030/可以访问JobTracker。</p>

<p>现在执行一个例子:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ mkdir input
</span><span class="line">$ cp conf/*.xml input/
</span><span class="line">
</span><span class="line">$ bin/hadoop fs -put intput input   # 把当前文件系统input目录复制为HDFS的input
</span><span class="line">$ bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+'  # 执行所有example.jar，后面的是参数
</span><span class="line">
</span><span class="line"># 一段时间后，执行完毕 #
</span><span class="line">$ bin/hadoop fs -get output output # 把HDFS中的output目录复制为当前文件系统的ouput
</span><span class="line">$ cat output/* # 打印结果
</span><span class="line">
</span><span class="line"># 或者直接对HDFS操作 #
</span><span class="line">$ bin/hadoop fs -ls output
</span><span class="line">$ bin/hadoop fs -cat output/*</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="wordcount">WordCount例子</h3>

<p><a href="http://hadoop.apache.org/docs/stable/mapred_tutorial.html" title="WordCount">WordCount</a>是hadoop中的另一个例子</p>

<p>Hadoop是通过<a href="http://wiki.apache.org/hadoop/HadoopMapReduce" title="MapReduce">MapReduce</a>机制来处理大数据的。Map阶段分割输入的数据，并整合成&lt;key,value&gt;的对应关系。每对&lt;key,value&gt;对送到Combiner做每个key的整合，当整合出一定数量的&lt;key,value&gt;后，&lt;key,value&gt;会送到Reducer做处理输出最终的&lt;key,value&gt;。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>按照<a href="http://hadoop.apache.org/docs/stable/mapred_tutorial.html" title="WordCount">WordCount</a>中的代码编辑WordCount.java，然后编译打包生成wordcount.jar:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ mkdir wordcount_classes
</span><span class="line">$ javac -classpath hadoop-hop-0.2-core.jar -d wordcount_classes WordCount.java
</span><span class="line">$ jar -cvf wordcount.jar -C wordcount_classes/ .</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后自行构造一些要统计的文件，放在input目录下。这时候注意，在执行了上一次例子后，如果想把输入文件还是放在HDFS的input下，要先清空原来的文件:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ bin/hadoop fs -rmr input/
</span><span class="line">$ bin/hadoop fs -rmr output/
</span><span class="line">
</span><span class="line">$ bin/hadoop fs -put input input # 把输入文件目录input重新放到HDFS中
</span><span class="line">
</span><span class="line">$ bin/hadoop jar wordcount.jar org.myorg.WordCount input output  # 执行wordcount.jar
</span><span class="line">
</span><span class="line"># 执行一段时间后完毕 #
</span><span class="line">
</span><span class="line">$ bin/hadoop fs -cat output/*  # 打印结果</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="section-2">结语</h3>

<p>尝试了一下Hadoop，还有更多有待研究
<br />
            <br />
            转载请注明原文链接
            <a href="http://www.goorockey.com/blog/2012/10/21/try-hadoop/">http://www.goorockey.com/blog/2012/10/21/try-hadoop/</a></p>

</div>


<div class="meta">
	<div class="date">








  


<time datetime="2012-10-21T23:47:00+08:00" pubdate data-updated="true">Oct 21<span>st</span>, 2012</time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/hadoop/'>hadoop</a>


</div>
	
	<div class="comments"><a href="#disqus_thread">Comments</a></div>
	
</div>
</article>

	<div class="share">
	<div class="addthis_toolbox addthis_default_style ">
		
		
		<a class="addthis_button_tweet"></a>
		
		
		
	</div>
	
</div>



<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2013

    Goorockey

</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'goorockeyslife';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://www.goorockey.com/blog/2012/10/21/try-hadoop/';
        var disqus_url = 'http://www.goorockey.com/blog/2012/10/21/try-hadoop/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//go.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-28958629-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>



</body>
</html>